{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T23:09:25.518921Z",
     "start_time": "2020-09-25T23:09:24.833765Z"
    }
   },
   "source": [
    "# NaLIR: Python Implementation Notebook -  Tutorial SBDD 2020\n",
    "\n",
    "### Autores: Altigran da Silva, Brandell Ferreira, Lucas Citolin e Paulo Martins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse Notebook mostraremos a implementação de uma Interface de Linguage Natural para Banco de Dados. Será apresentada a arquitetura geral do Sistema, e para cada módulo, será listado o que recebem como entrada, e o que geram como saída. Além disso, mostraremos detalhes de implementação que são interessantes em cada módulo. Ao final, mostraremos alguns exemplos de consultas para as quais o NaLIR consegue obter uma SQL válida. É importante ressaltar que apenas portamos o código para Python, o código original em Java se encontra neste [repositório](https://github.com/umich-dbgroup/NaLIR)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='arquitetura_geral'></a>\n",
    "## Arquitetura Geral\n",
    "\n",
    "O NaLIR é uma Interface de Lingaugem Natural que utiliza uma estrutura derivada do Parser de Dependência para traduzir as consultas de linguagem natural para uma linguagem estruturada de consulta de banco de dados (SQL). Além de utilizar o Parser de Dependência, o NaLIR também utiliza interações com o usuário para corrigir possíveis erros na estrutura da árvore de Dependência e nos mapeamentos padrões escolhidos das palavras da consulta para elementos de Banco de Dados.\n",
    "\n",
    "Como podemos ver na figura Abaixo, A arquitetura do NaLIRpossui **5** Componentes: **Dependecy Parser**, **Query Node Mapper**, **Query Tree Strucutre Adjustor**, **Query Translator** e **Interative Comunicator**. O **Depency Parser** recebe  a consulta do usuário,e repassa a entrada para o parser de Dependêcia de Stanford. Após retirar gerar a Árvore de Depência, o **Query Node Mapper** é reponsável por mapear os nós da árvore de dependência para elementos da estrutura de uma SQL.\n",
    "\n",
    "Após a escolha dos mapementos, o **Interactive Communicatior** entra em ação pela primeira vez, fornecendo para o usuário os candidatos encontrados pelo **Query Node Mapper**. Após o usuário escolher os mapeamentos para cada Nó, **Query Tree structure Adjustor** executa um algoritmo para modificar a estrutura da Árvore para que a conversão para uma consulta SQL seja facilitada. Tais modificações são feitas seguindo uma gramática. A saída dessa etapa é uma lista de árvores, ordenadas por uma pontuação que indica o quão correta está a árvore e a relação entre os elementos do banco de dados que os nós referenciam.\n",
    "\n",
    "Pela Segunda vez, o **Interactive Comunicator** entra em ação, para que o usuário escolha qual árvore será escolhida pelo usuario. Após isso, **Query Tree Structure Adjustor** insere nós na árvore selecionada pelo usuário com o intuito de retirar possíveis elipses da consulta. Pela última vez **Interactive Commnunicator** mostra ao usuário as inserções feitas. Após a ação do usuário, a árvore de consulta é repassada para o **Query Tree Translator** que efetivamente converte a árvore para uma SQL válida.\n",
    "\n",
    "Na nossa implementação, **não portamos o Interactive Communicator**, assim o único fluxo possível é aquele em que o **NaLIR utiliza todos os mapeamentos padrões** para resolver a consulta.\n",
    "\n",
    "![Arquitetura Geral](imgs/OverallDiagram.png)\n",
    "\n",
    "É importante salientar que apesar de apenas quatro módulos estarem presentes na arquitetura do NaLIR, alguns módulos auxiliares foram implementados,como o que gerencia o acesso ao Banco de Dados. Apesar deste módulo estar presente nas entrelinhas do fluxo na Arquitetura mostrada acima, foi preciso implementá-lo para que fosse possível a construção do Sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuração do Cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nalir import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro passo é **instanciar** o objeto de configuração responsável por carregar os arquivos requeridos para que a execução do Nalir possa ser feita. A configuração é feita a partir de um objeto JSON, cujo as propriedades devem ser:\n",
    "\n",
    "| Propriedade | Tipo | Descrição |\n",
    "| :-- | :-: | :-- | \n",
    "| `connection` | Object | Armazena as configurações de conexão com o Banco de dados |\n",
    "| `connection.host`|  String | Host para a conexão com o Banco de Dados |\n",
    "| `connection.password`| String | Senha para conectar com o Banco de Dados |\n",
    "| `connection.user` | String | Usuario de Banco de Dados|\n",
    "| `connection.database` | String | Nome do Banco de Dados utilizado |\n",
    "| `logginMode` | String | Nivel de Login da Aplicação|\n",
    "| `zfiles_path`| String | Diretório onde se encontra os arquivos de configuração do NaLIR|\n",
    "| `jars_path` | String | Diretório onde se encontra os jars necessários para a execução do NaLIR |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T23:09:25.524674Z",
     "start_time": "2020-09-25T23:09:25.520353Z"
    }
   },
   "outputs": [],
   "source": [
    "config_json_text = '''{\n",
    "    \"connection\":{\n",
    "        \"host\": \"localhost\",\n",
    "        \"password\":\"desenvolvimento123\",\n",
    "        \"user\":\"nalir\",\n",
    "        \"database\":\"mas\"\n",
    "    },\n",
    "    \"loggingMode\": \"ERROR\",\n",
    "    \"zfiles_path\":\"/home/novello/nalir-sbbd/zfiles\",\n",
    "    \"jars_path\":\"/home/novello/nalir-sbbd/jars/new-jars\"\n",
    "}\n",
    "'''\n",
    "config = ConfigHandler(reset=True,config_json_text=config_json_text)\n",
    "#config = ConfigHandler(reset=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após colocar todas as configurações necessárias e criar o objeto, é preciso criar uma instância do módulo que gerencia o acesso ao Banco de Dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T23:09:25.849306Z",
     "start_time": "2020-09-25T23:09:25.526005Z"
    }
   },
   "outputs": [],
   "source": [
    "rdbms = RDBMS(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para exemplificar passo a passo como os módulos do NaLIR interagem com a consulta, utilizaremos a consulta ''return me the authors who have a paper in VLDB conference before 2002 after 1995.''."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T23:09:25.855589Z",
     "start_time": "2020-09-25T23:09:25.852274Z"
    }
   },
   "outputs": [],
   "source": [
    "query_line='return me the authors who have a paper in VLDB conference before 2002 after 1995.'\n",
    "query = Query(query_line,rdbms.schema_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stanford Dependency Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na inicialização da classe `StanfordParser` executamos 3 passos para transformar a consulta em uma árvore de dependência. Cada passo é representado por uma função no código a seguir:\n",
    "\n",
    "``` python\n",
    "     def __init__(self,query,config):\n",
    "        \n",
    "        #....\n",
    "        \n",
    "        self.parse(query)\n",
    "        self.build_tree(query)\n",
    "        self.fix_conj(query)\n",
    "        \n",
    "        #....\n",
    "```\n",
    "\n",
    "A função `parse(query)` executa o Parser de Dependência na consulta recebida, enquanto as outras `build_tree` e `fix_conj` são responsáveis por adaptar a estrutura para uma estrutura `ParseTree` definida dentro do pacote. A seguir mostramos como a função `build_tree` constrói a Árvore de Dependência a partir das dependências extraídas pelo Parser de Stanford.\n",
    "\n",
    "``` python\n",
    "    def build_tree(self,query):\n",
    "        query.parse_tree = ParseTree()\n",
    "        done_list = [False] * len(query.tree_table)\n",
    "        i = 0\n",
    "\n",
    "        for tree_table_item in query.tree_table:\n",
    "            if tree_table_item[PARENT_IDX] == 0:\n",
    "                done_list[i] = True\n",
    "                query.parse_tree.build_node(tree_table_item)\n",
    "            i+=1\n",
    "\n",
    "        finished = False\n",
    "        while not finished:\n",
    "            i = 0\n",
    "            for i in range(len(query.tree_table)):\n",
    "                if not done_list[i]:\n",
    "                    if query.parse_tree.build_node(query.tree_table[i]):\n",
    "                        done_list[i] = True\n",
    "                        break\n",
    "\n",
    "\n",
    "            finished = True\n",
    "            for done_list_item in done_list:\n",
    "                if not done_list_item:\n",
    "                    finished = False\n",
    "                    break\n",
    "\n",
    "```\n",
    "\n",
    "A tabela `query.tree_table` é criada em `parse(query)`. `fix_conj()` corrige relações de conjunção (quando duas palavras estão conectadas por \"e\" ou \"ou\"). Abaixo temos o exemplo da saída do módulo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T23:09:27.104088Z",
     "start_time": "2020-09-25T23:09:25.857005Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "StanfordParser(query,config)\n",
    "query.parse_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**: O graph vizualitation possui o programa [Graphviz](https://graphviz.org/)  como dependêcia, logo ele precisa ser instalado. Verifique no site como é possível baixá-lo para seu sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T23:09:27.135015Z",
     "start_time": "2020-09-25T23:09:27.105509Z"
    }
   },
   "outputs": [],
   "source": [
    "query.parse_tree.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Mapper\n",
    "\n",
    "Como dito em [Arquitetura Geral](#arquitetura_geral), o módulo de **Query Tree Node Maper**, que no código é repesentado por `NodeMapper`, possui a função de mapear os nós da árvore de dependência para os elementos da estrutura SQL. Os tipos de nós, são: \n",
    "\n",
    "\n",
    "<a id=\"tipo_no\"></a>\n",
    "\n",
    "| Tipo de Nó |Componente SQL Correspondente |\n",
    "| :-- | :-- |\n",
    "| Select Node (SN) |palavra reservada SQL : SELECT |\n",
    "| Operator Node (ON) | operadores ( !=, >,<,=,  contains) |\n",
    "| Function Node (FN) | Funções de Agregação (AVG) |\n",
    "| Name Node (NN) | Nome de Relação ou de Atributo |\n",
    "| Value Node (VN) | Valor de um determinado atributo |\n",
    "| Quantifier Node (QN) | Palavras como ALL, ANY, EACH |\n",
    "| Logic Node (LN) | Operadores Booleanos (AND, OR, NOT) |\n",
    "\n",
    "Excluindo os Nós **Name** e **Value** nodes, todos os outros são definidos a partir de um arquivo xml. Esse arquivo se encontra dentro do diretório `zfiles`, como o nome de `tokens.xml` e possui o seguinte formato: \n",
    "``` xml\n",
    "<types>\n",
    "   <!-- Command Token, verb -->\n",
    "   <CMT_V>\n",
    "      <phrase>\n",
    "         tell\n",
    "         <example>Tell me all the books published in year 1993.</example>\n",
    "      </phrase>\n",
    "      <phrase>\n",
    "         give\n",
    "         <example>Give me all the books published in year 1993.</example>\n",
    "      </phrase>\n",
    "      <phrase>\n",
    "         return\n",
    "         <example>Return all the books published in year 1993.</example>\n",
    "      </phrase>\n",
    "   </CMT_V>\n",
    "   <!-- Function Token, adjective -->\n",
    "   <FT>\n",
    "      <phrase>\n",
    "         minimum\n",
    "         <function>min</function>\n",
    "         <example>Find the books with the minimum price.</example>\n",
    "      </phrase>\n",
    "      <phrase>\n",
    "         most\n",
    "         <function>max</function>\n",
    "      </phrase>\n",
    "      <phrase>\n",
    "         biggest\n",
    "         <function>max</function>\n",
    "      </phrase>\n",
    "      <phrase>\n",
    "         least\n",
    "         <function>min</function>\n",
    "      </phrase>\n",
    "   </FT>\n",
    "   <!-- Operator Token, adj -->\n",
    "   <OT>\n",
    "      <phrase>\n",
    "         earlier\n",
    "         <operator>&lt;</operator>\n",
    "         <example>Find all the books of Ayn Rand, where the year of each book is earlier than the year of \"Fountain Head\".</example>\n",
    "      </phrase>\n",
    "      <phrase>\n",
    "         later\n",
    "         <operator>&gt;</operator>\n",
    "         <example>Find all the books of Ayn Rand, where the year of each book is later than the year of \"Fountain Head\".</example>\n",
    "      </phrase>\n",
    "   </OT>\n",
    "</types>\n",
    "```\n",
    "\n",
    "Assim, se quem estiver utilizando o Sistema quiser aumentar a granularidade e a interpretação do NaLIR, basta aumentar a lista de tokens deste arquivo. O código a seguir mostra as etapas de função do mapeamento.\n",
    "\n",
    "``` python \n",
    " \n",
    " def phrase_process(query, db, config):\n",
    "        # ...\n",
    "        \n",
    "        NodeMapper.tokenizer(query, tokens)\n",
    "        NodeMapper.delete_useless(query)\n",
    "        NodeMapper.map(query,db)\n",
    "        NodeMapper.individual_rank(query)\n",
    "        group_ranking = NodeMapper.group_ranking(query,db)\n",
    "        return NodeMapper.group_ranking_to_df(group_ranking)\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "A primeira etapa `NodeMapper.tokenizer(query, tokens)` utiliza os tokens carregados do arquivo `tokens.xml` e mapeia corretamente os nós que exercem uma função diferente de Name Nodes e Value Nodes.  Nessa função a diferenciação acontece baseado na função sintática da palavra e na presença da palavra no arquivo de tokens. Por exemplo, se a palavra não estiver presente em tokens, e for um substantivo próprio ou comum, adjetivo ou um número cardinal, essa etapa assinala um tipo intermediario para o nó, `NTVT`. Isso indica para as fases seguintes que esse nós, apesar de não terem um tipo final, podem ser candidatos a algum mapeamento (Name Node ou Value Node).\n",
    "\n",
    "Em `delete_useless` todos os nós que não possuem tipo (`NA`) são deletados. Já em `map`, que será mostrado a seguir, busca todos os elementos de esquema e valores de banco de dados que podem fazer referencia aos nós \"candidatos\" a Name e Value Nodes dentro da árvore. \n",
    "\n",
    "\n",
    "``` python\n",
    "    def map(query, db):\n",
    "    parse_tree = query.parse_tree\n",
    "    all_nodes = parse_tree.all_nodes\n",
    "\n",
    "    for i in range(len(all_nodes)):\n",
    "        tree_node = all_nodes[i]\n",
    "        if tree_node.token_type == 'NTVT' or tree_node.token_type == 'JJ':\n",
    "            db.is_schema_exist(tree_node)\n",
    "            db.is_text_exist(tree_node)\n",
    "\n",
    "            if len(tree_node.mapped_elements) == 0:\n",
    "                tree_node.token_type = 'NA'\n",
    "\n",
    "        elif tree_node.token_type == 'VT':\n",
    "            OT = '='\n",
    "            if tree_node.parent.token_type == 'OT':\n",
    "                OT = tree_node.parent.function\n",
    "            elif len(tree_node.children) == 1 and tree_node.children[0].token_type == 'OT':\n",
    "                OT = tree_node.children[0].function\n",
    "            db.is_num_exist(OT, tree_node)\n",
    "            tree_node.token_type = 'VTNUM'\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "Os candidatos para Name Nodes são recuperados em `db.is_schema_exist` e  para Value Nodes em `db.is_text_exist` e `db.is_num_exist`.  \n",
    "\n",
    "A função `individual_ranking` é responsável por calcular a similaridade entre um dado nó e os elementos de esquema mapeados para o mesmo, enquanto a função ``group_ranking`` é responsável por identificar a melhor configuração de mapeamento para todos nós. Essa escolha é feita baseada em:\n",
    "\n",
    " - Em como os nós estão dispostos na árvore\n",
    " - Na relação entre os elementos de esquema mapeados para os nós\n",
    " \n",
    " Essa relação é calculada no Grafo de Esquema, usando Djkistra para calcular a distãncia entre os elementos do esquema. Ao final desse processo, `group_ranking` classifica os nós candidatos `NTVT` em Name Nodes (`NT`) ou Value Nodes (`VT`).  \n",
    "\n",
    "Abaixo segue o exemplo da saida da função que executa o mapeamento dos nós."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T23:09:38.288137Z",
     "start_time": "2020-09-25T23:09:27.137697Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "NodeMapper.phrase_process(query,rdbms,config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T23:09:38.327908Z",
     "start_time": "2020-09-25T23:09:38.291260Z"
    }
   },
   "outputs": [],
   "source": [
    "query.parse_tree.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Entity Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse módulo é a primeira fase do **Tree Strucutre Adjustor**. Antes de gerar as árvores seguindo a gramática, **Entity Resolution** verifica quais nós referenciam o mesmo atributo na árvore. Essa relação é utilizada tanto na geração de árvores derivadas, quanto na pontuação das árvores. Segue abaixo o código da função ``entity_resolute``, seguido da saída da mesma: \n",
    "\n",
    "\n",
    "``` python \n",
    "\n",
    "def entity_resolute(query):\n",
    "    query.entities = []\n",
    "    nodes = query.parse_tree.all_nodes\n",
    "    for i in range(len(nodes)):\n",
    "        left = nodes[i]\n",
    "        if left.get_choice_map() == None:\n",
    "            continue\n",
    "        left_map = left.get_choice_map().schema_element\n",
    "        for j in range(i+1, len(nodes)):\n",
    "            right = nodes[j]\n",
    "            if right.get_choice_map() == None:\n",
    "                continue\n",
    "            right_map = right.get_choice_map().schema_element\n",
    "            if left_map == right_map:\n",
    "                if left.token_type == \"VTTEXT\" and left.token_type == \"VTTEXT\":\n",
    "                    if left.label == right.label:\n",
    "                        entity_pair = EntityPair(left, right)\n",
    "                        query.entities.append(entity_pair)\n",
    "                    else:\n",
    "                        continue\n",
    "                if left.token_type == \"VTTEXT\" and right.token_type == \"NT\" or\\\n",
    "                 left.token_type == \"NT\" and right.token_type == \"VTTEXT\" or\\\n",
    "                 left.token_type == \"NT\" and right.token_type == \"NT\":\n",
    "                    if abs(left.word_order - right.word_order) > 2:\n",
    "                        continue\n",
    "                    else:\n",
    "                        entity_pair = EntityPair(left, right)\n",
    "                        query.entities.append(entity_pair)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T23:09:38.419847Z",
     "start_time": "2020-09-25T23:09:38.329289Z"
    }
   },
   "outputs": [],
   "source": [
    "entity_resolute(query)\n",
    "query.entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Structure Adjustor\n",
    "\n",
    "Este módulo é responsável por:\n",
    " * Verificar se a árvore gerada condiz com a gramática especificada\n",
    " * Gerar Árvores variantes da Árvore de Parser original que seguem a gramática\n",
    " * Ranquear todas as Árvores, e escolher a com maior pontuação para a etapa de tradução.\n",
    " \n",
    "A gramática que deve ser seguida para as árvores é a seguinte:\n",
    "```\n",
    "\n",
    "Q -> (SClause)(ComplexCondition)*\n",
    "SClause -> SELECT + GNT\n",
    "ComplexCondition -> ON + (leftSubtree*rightSubtree)\n",
    "leftSubtree -> GNP\n",
    "rightSubtree -> GNP |VN | MIN | MAX\n",
    "GNP -> (FN + GNP) | NP\n",
    "NP -> NN + (NN)*(Condition)*\n",
    "Condition-> VN | (ON + VN)\n",
    "```\n",
    "\n",
    "Em que: \n",
    "* VN, NN, FN, ON são tipos de nós referenciados na [tabela de tipos de nós](#tipo_no)\n",
    "* `+` representa relações de pai-filho entre os nós\n",
    "* `*` representa relações de irmão entre os nós\n",
    "\n",
    "\n",
    "A função `tree_structure_adjust`, listada a seguir, é a responsável por executar o processo de geração das árvores.\n",
    "\n",
    "``` python\n",
    "    \tdef tree_structure_adjust(query,  db):\n",
    "\t\tquery.adjusting_trees = []\n",
    "\t\tquery.invalid = []\n",
    "\t\tpre_trees = {}\n",
    "   \n",
    "\t\tTreeStructureAdjustor.adjust(query, db,False, pre_trees)\n",
    "\t\tif len(query.adjusting_trees) == 0 or (len(query.adjusting_trees) > 0 and query.adjusting_trees[0].cost > 3):\n",
    "\t\t\tmax_min = False\n",
    "\t\t\tfor node in query.parse_tree.all_nodes:\n",
    "\t\t\t\tif node.function == 'max' or node.function == 'min':\n",
    "\t\t\t\t\tmax_min = True\n",
    "\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\tif max_min:\n",
    "\t\t\t\tTreeStructureAdjustor.adjust(query, db, True, pre_trees)\n",
    "\n",
    "\t\tadjusted_trees = query.adjusting_trees\n",
    "\t\tadjusted_trees.sort(key=lambda elem : ((elem.weight * 100) - elem.cost) * -1 )\n",
    "\t\tfor i  in range(len(adjusted_trees)):\n",
    "\t\t\tadjusted_tree = adjusted_trees[i]\n",
    "\n",
    "\t\t\tfor j in range(len(adjusted_tree.all_nodes)):\n",
    "\t\t\t\tnode = adjusted_trees[i].all_nodes[j]\n",
    "\t\t\t\tnode.children.sort(key=lambda elem: elem.node_id)\n",
    "\t\t\thash(adjusted_tree)\n",
    "\n",
    "\n",
    "\t\tlinked_list = []\n",
    "\t\ti = 0\n",
    "\t\twhile i  < len(adjusted_trees):\n",
    "\t\t\tif adjusted_trees[i].hash_num in linked_list:\n",
    "\t\t\t\tadjusted_trees.pop(i)\n",
    "\t\t\t\ti-=1\n",
    "\t\t\telse:\n",
    "\t\t\t\tlinked_list += [adjusted_trees[i].hash_num]\n",
    "\t\t\ti+=1\n",
    "\n",
    "\t\tTreeStructureAdjustor.build_adjusted_trees(query)\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "Como podemos observar, primeiramente é gerado uma série de árvores, chamadas `adjusting_trees`. Depois de ordenarmos estas árvores intermediárias, ordenamos todos os filhos de todos os nós, e retiramos as árvores repetidas da lista. A partir dai, geramos a lista final de árvores, no método `build_adjusted_trees`. A seguir, verificamos a saída final do método."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T23:09:39.566174Z",
     "start_time": "2020-09-25T23:09:38.422232Z"
    }
   },
   "outputs": [],
   "source": [
    "TreeStructureAdjustor.tree_structure_adjust(query,rdbms)\n",
    "query.query_tree.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainer\n",
    "\n",
    "Este módulo, é a última etapa de **Tree Strucuture Adjustor**. Após selecionar a árvore com maior pontuação, este módulo insere nós com o intuito de facilitar a tradução da consulta para linguagem natural para a SQL. Outro objetivo desta etapa é retirar elipses da consulta.  O código asseguir, mostra que esta função apenas itera sobre os nós da árvore e verifica se pode inserir outros nós que já estão na árvore, em um dos seus nós filhos.\n",
    "\n",
    "\n",
    "\n",
    "```python \n",
    "  def explain(query):\n",
    "    for i in query.adjusted_trees:\n",
    "        nl = explain_tree(i)\n",
    "        query.nl_sentence.append(nl)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain(query)\n",
    "query.query_tree.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Translator\n",
    "\n",
    "O último módulo da arquitetura do NaLIR, é responsável por receber a Árvore Consulta (`query_tree`), gerada pelo **Query Tree Strucutre Adjustor** e retornar a SQL correspondente.  A função `translate`, listada a seguir, é a responsável por executar esse processo dentro do módulo. \n",
    "\n",
    "Como vemos no código a estrutura utilizada para converter a árvore em uma string SQL é uma estrutura chamada `block`. Cada `block` identifica um nivel de consulta. Assim, consultas que não possuem subconsultas, possuem apenas um bloco. Consultas que possuem agregação, ou consultas aninhadas, possuem dois ou mais blocos.\n",
    "\n",
    "```python\n",
    "def translate(query, db):\n",
    "    pre_structure_adjustor(query)\n",
    "    if len(query.query_tree.all_nodes) < 2:\n",
    "        return\n",
    "    query.blocks = []\n",
    "    block_split(query)\n",
    "    query.blocks[0].node_edge_gen(query.main_block, query.query_tree, query.graph)\n",
    "    query.blocks[0].translate(query.main_block, query.query_tree)\n",
    "    query.translated_sql = query.blocks[0].sql\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T23:09:39.725094Z",
     "start_time": "2020-09-25T23:09:39.638591Z"
    }
   },
   "outputs": [],
   "source": [
    "translate(query, rdbms)\n",
    "print(query.translated_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outras consultas que também podem ser executadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    'return me the homepage of PVLDB.',\n",
    "    'return me the homepage of \"H. V. Jagadish\".',\n",
    "    'return me the abstract of \"Making database systems usable\".',\n",
    "    'return me the year of \"Making database systems usable\"',\n",
    "    'return me all the keywords.',\n",
    "    'return me the number of the organizations in \"North America\".',\n",
    "    'return me the number of keywords in VLDB conference.',\n",
    "    'return me the number of the organizations.',\n",
    "    'return me the number of authors of \"Making database systems usable',\n",
    "    'return me the area of the VLDB conference.',\n",
    "    'return me the organization \"H. V. Jagadish\" is in.',\n",
    "    'return me all the organizations in Databases area.'\n",
    "]\n",
    "\n",
    "sql_queries = []\n",
    "for query in queries:\n",
    "    sql_query = run_query(query, rdbms, config)\n",
    "    sql_queries += [sql_query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Teste você mesmo !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'return me all the organizations in Databases area.' # ponha sua consulta aqui\n",
    "run_query(query, rdbms, config)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "markdown",
    "format_version": "1.2",
    "jupytext_version": "1.4.2"
   }
  },
  "kernelspec": {
   "name": "Python 3.8.5 64-bit",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}